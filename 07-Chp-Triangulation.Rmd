---
bibliography: bibliography/references.bib
csl: bibliography/nature.csl
output:
  bookdown::word_document2: 
      toc: false
      toc_depth: 3
      reference_docx: templates/word-styles-reference-01.docx
      number_sections: false 
  bookdown::pdf_document2:
    template: templates/brief_template.tex
  bookdown::html_document2: default
documentclass: book
---

```{block type='savequote', include=knitr::is_latex_output(), quote_author='(ref:tri-quote)', echo = TRUE}
Next on my list of features to be specially considered I would place the consistency of the observed association. Has it been repeatedly observed by different persons, in different places, circumstances and times?
```
(ref:tri-quote) --- Austin Bradford Hill, 1965 [@hill1965]

<!-- TODO Add this to the Chapter summary in the introduction -->

<!-- ### Triangulation  -->

<!-- TODO Have a look at this - potentially move to triangulation chapter -->

<!-- One key question for which multiple distinct sources of evidence were available were those looking at Laz -->

<!-- Consideration of the potential impact of the magnitude and direct of residual confounders/bias is not a major stretch from what is already happening in the assessment of the quality of evidence (GRADE) framework. Within GRADE, the overall quality of evidence can be upgraded when there is deemed to be unmeasured or residual confounding variables which reduce the. For example, if the propensity to treatment is related to comorbidity burden, but those on treatment still have better outcomes then those on control, it is likely that the true effect of the intervention is being underestimated. [@guyatt2011] -->

# Aetiological triangulation across new and existing evidence sources {#tri-heading}

&nbsp;

\minitoc <!-- this will include a mini table of contents-->

```{r, echo = FALSE, warning=FALSE, message=FALSE}
source("R/helper.R")
knitr::read_chunk("R/03-Code-Systematic-Review.R")
knitr::read_chunk("R/05-Code-CPRD-Analysis.R")
knitr::read_chunk("R/06-Code-IPD-Analysis.R")
knitr::read_chunk("R/07-Code-Triangulation-Analysis.R")
doc_type <- knitr::opts_knit$get('rmarkdown.pandoc.to') # Info on knitting format
```

\newpage

::: {.laybox data-latex=""}
## Lay summary {-}

<!-- Triangulation is the practice of using multiple sources of evidence to provide more reliable answers to a research question. Different sources of evidence will have different limitations. If the result from each source points towards the same answer, this improves our confidence in the conclusion. -->

__TBC__

:::

<!-- Triangulation is the practice of using multiple sources of evidence to provide more reliable answers to a research question. Different sources of evidence will have different limitations. If the result from each source points towards the same answer, this improves our confidence in the conclusion. -->

&nbsp;<!----------------------------------------------------------------------->  

## Introduction {#triangulation-overview}

Aetiological triangulation, or simply triangulation, is the process of comparing and contrasting across different sources of evidence. Triangulation is broadly comparable to Bradford-Hill's criteria of "consistency", that is the replication of an observed relationship across several different contexts,[@hill1965] where contexts are assumed to have different underlying bias structures. More formally it can be defined as: 

> The practice of strengthening causal inferences by integrating results from several different approaches, where each approach has different (and assumed to be largely unrelated) key sources of potential bias.[@lawlor2016]

This approach represents a significant step forward from the current practice of synthesising evidence from only one type of study (e.g. randomised controlled trials (RCTs), non-randomised studies of exposures (NRSE) or interventions (NRSI)). The most common implementation of this method to date has been in the form of _qualitative triangulation_ - that is the identification and narrative comparison of diverse evidence sources with respect to their underlying bias structures.[@lawlor2016]

However, qualitative triangulation faces issues at scale. There is a need to include all evidence to avoid potential confirmation bias,[@dubroff2018] yet as the number of evidence sources increases, it is not possible to narratively compare and contrast across multiple results in any meaningful way. This fact is illustrated by previous exemplars of triangulation only considering a small number of individual results.[@ference2014; @lawlor2016] To overcome this limitation, some attempts have considered the output of a meta-analysis of similarly-designed studies to be a single source of evidence, and have assessed bias in relation to this summary result. While this approach keeps the number of individual sources of evidence manageable, it loses useful information on the specific biases inherent to each result contributing to the summary estimate. For example, while it may be true that all non-randomised studies share some minimal level of bias, competing extents and directions of bias in individual results may be masked by the use of summary estimates. In addition, previous attempts at qualitative triangulation have not systematically assessed the indirectness of the results, that is the differences between the question of interest and the question addressed by a study.

Taken together, these limitations to qualitative triangulation detail a need for a more systematic way to integrate across multiple evidence sources as the number of individual results contributing to the exercise increases. One such approach is _quantitative triangulation_, where results from different evidence sources are combined numerically while accounting for the key sources of bias and indirectness in each. This chapter, in addition to providing a narrative comparison of the existing and new evidence identified by this thesis, builds on recent developments in risk-of-bias assessment and methods for bias-/indirectness-adjusted meta-analysis to propose a generalised framework for quantitative triangulation. The framework, along with the methodological challenges to its implementation, is illustrated via two case studies examining the causal effect of lipids on dementia outcomes.

&nbsp;<!----------------------------------------------------------------------->  

## Data sources {#tri-data-sources}

The triangulation exercises presented in this chapter draw on the research produced in each of the preceding chapters. More specifically, this chapter builds on the comprehensive systematic review of existing evidence presented in Chapters \@ref(sys-rev-methods-heading) & \@ref(sys-rev-results-heading). This evidence base is then supplemented by new evidence on the association of statin use with dementia outcomes in the CPRD (Chapter \@ref(cprd-analysis-heading)) and the association of lipids with dementia outcomes in previously unanalysed datasets accessed via the DPUK (Chapter \@ref(ipd-heading)).

Table \@ref(tab:thesisOverview-table) summarises the research question each data source has attempted to address, the exposures and outcomes considered in each case, and the contribution of each chapter to the triangulation exercise presented here.

<!-- TODO Consider adding AD as an outcome to the IPD row, depending on which result you want to use. -->

\blandscape
<!----------------------------------------------------------------------------->
(ref:thesisOverview-caption) Summary of studies included in this thesis and used as evidence sources in this triangulation exercise. Note, Chapter \@ref(sys-rev-tools-heading) is intentionally not included in this table, as it describes a research tool rather than a research study.

(ref:thesisOverview-scaption) Summary of research designs included in this thesis

```{r thesisOverview-table, message=FALSE, results="asis", echo = FALSE}
```
<!----------------------------------------------------------------------------->
\elandscape

Additionally, both the qualitative and quantitative triangulation exercises used the the detailed risk-of-bias assessments performed and presented as part of the systematic review (Chapters \@ref(sys-rev-methods-heading) & \@ref(sys-rev-results-heading)). Similarly, risk-of-bias assessments were performed for each new source of evidence presented in this thesis. The risk of bias tools used to assess each result are described in detail in Section \@ref(risk-of-bias), but in summary, RCTs were assessed using the RoB 2 tool;[@sterne2019] NRSI using the ROBINS-I tool;[@sterne2016] NRSE using an early adapted version of the ROBINS-E tool (see Section \@ref(rob-tools-nrse));[@morganr2020; @french2019] and MR studies using the Mamluk et al. tool.[@mamluk2020] 

&nbsp;<!----------------------------------------------------------------------->  

## Qualitative (narrative) triangulation {#qual-tri}

```{r rctStatinDementia, include = FALSE, message=FALSE, warning=FALSE}
```

```{r Hypercholesterolemia, include = FALSE, message=FALSE, warning=FALSE}
```

```{r mrLipidsAD, include = FALSE, message=FALSE, warning=FALSE}
```

```{r LipidsSD, include = FALSE, message=FALSE, warning=FALSE}
```

```{r lipidFrationsSetup, include = FALSE, message=FALSE, warning=FALSE}
```

```{r obsStatins, include = FALSE, message=FALSE, warning=FALSE}
```

```{r obsFibrates, include = FALSE, message=FALSE, warning=FALSE}
```

```{r mrStatins, include = FALSE, message=FALSE, warning=FALSE}
```

```{r azd-text, echo = FALSE}
```

```{r prepIPDFigures,include=F}
```

As part of a qualitative triangulation of the new and existing evidence identified by this thesis, all information sources were initially grouped by outcome, and the findings from each source were narratively compared and contrasted. Potential reasons for heterogeneity between study designs were examined with specific reference to the risk-of-bias in each. 

&nbsp;<!----------------------------------------------------------------------->  

#### All-cause dementia

Analysis of lipid levels across both the systematic review (Chapter \@ref(sy-rev-results-heading)) and the IPD analysis (Chapter \@ref(ipd-analysis-heading)) both found extremely weak evidence for an association of any lipid fraction with all-cause dementia (TC `r obsLipids$Dementia_TC$estimate`; LDL-c `r obsLipids$Dementia_LDL$estimate`; HDL-c `r obsLipids$Dementia_HDL$estimate`; triglycerides `r obsLipids$Dementia_TG$estimate`). Similarly, meta-analysis of studies identified by the review which examined a binary hypercholesterolemia provided weak evidence for an association of this risk factor with Alzheimer's disease (`r obsHyperchol$Dementia$estimate`). Finally, a meta-analysis of RCTs of statin use (`r rct_statin_acd`) and of MR analyses of genetic instruments that mimic statin use (`r mrStatin$Dementia$estimate`) both found weak evidence of an association, providing indirect evidence on the effect of lipid lowering on this outcome.

In contrast, the meta-analysis of NRSI of statin use found a slight protective effect (`r obsStatins$Dementia$estimate`), though many of the studies in this analysis were found to be at risk of immortal time bias, which would be expected to favour the intervention. Finally, analysis of the association of statin use with all-cause dementia in the CPRD (Chapter \@ref(cprd-analysis-heading)) found evidence of a harmful association (`r anydem_sta_text`), though this is likely to be driven by the substantial confounding by indication identified in the vascular dementia subgroup.

For fibrates, an alternative lipid-regulating agent, there was some evidence of an increased risk of all-cause dementia in the CPRD (`r anydem_fib_text`), though this did not replicate in the meta-analysis of previous studies examining the association of fibrates and all-cause dementia (`r obsFibrates$Dementia$estimate`).

&nbsp;<!----------------------------------------------------------------------->  

#### Alzheimer's disease

Meta-analysis of lipid levels in the systematic review found extremely weak evidence for an association of any lipid fraction with Alzheimer's disease (TC `r obsLipids$AD_TC$estimate`; LDL-c `r obsLipids$AD_LDL$estimate`; HDL-c `r obsLipids$AD_HDL$estimate`; triglycerides `r obsLipids$AD_TG$estimate`). Similarly, meta-analysis of studies examining a binary hypercholesterolemia provided weak evidence for an association of this risk factor with Alzheimer's disease (`r obsHyperchol$AD$estimate`). A meta-analysis of MR analyses of genetic instruments that mimic statin use found weak evidence for an association of lipid lowering with Alzheimer's disease (`r mrStatin$AD$estimate`).

In contrast, the meta-analysis of NRSI of statin use found a slight protective effect on this outcome (`r obsStatins$AD$estimate`), though similar to the all-cause dementia outcome, many of the studies in this analysis were found to be at risk of immortal time bias. However, the CPRD analysis, which attempted to account for this potential bias through the use of time-varying treatment indicator, found weak evidence for an effect (`r probad_sta_text`). This validity of this finding was limited by the potential for differential misclassification on the basis of the exposure in the CPRD analysis.

Finally, the IPD analysis provided no additional information on the Alzheimer's disease outcome, as a previously published analysis examined the association of lipid levels with this outcome in the Whitehall II cohort. The published analysis was included in the meta-analysis of NRSE, the results of which are presented above.

&nbsp;<!----------------------------------------------------------------------->  

#### Vascular dementia

There was a general absence of existing evidence on vascular dementia outcomes. Meta-analysis of published results was only possible for the total cholesterol lipid fraction (`r obsLipids$VaD_TC$estimate`). A meta-analysis of studies examining hypercholesterolemia also found weak evidence for an association with vascular dementia (`r obsHyperchol$VaD$estimate`). Similarly, a meta-analysis of statin use found weak evidence for an effect on this outcome (`r obsStatins$VaD$estimate`). The CPRD analysis found evidence for a harmful association of statin use (`r vasdem_sta_text`), though this finding is likely to be the result of severe confounding by indication related to vascular factors, as identified through the use of control outcomes. 

The IPD analysis provided supporting evidence for the absence of an effect of any fraction on vascular dementia, with the sole exception of triglycerides. Raised triglycerides were associated with an increased incidence of vascular dementia across two previously unanalysed cohorts (`r ipd_vasdem`), though there is the potential for uncontrolled confounding due to the limited information on covariates available. With respect to evidence on treatments for hypertriglyceridemia, examination of fibrates in the CPRD provided weak evidence of an association with vascular dementia (`r vasdem_fib_text`). 

&nbsp;<!----------------------------------------------------------------------->  

## Quantitative triangulation

The qualitative comparison presented above identified no consistent effect of any lipid fraction on any dementia outcome across the evidence sources presented in this thesis. However, it is clear that this qualitative approach faces difficulties in interpretation when the number of individual results available is large, as discussed in the introduction to this chapter. This is true even when using summary estimates from meta-analyses of primary studies, which sacrifice valuable information on the biases inherent to each individual result. 

In the following section, I propose and apply a novel quantitative triangulation framework to address these limitations. This approach incorporates recent advancements in the way that bias in results is assessed (namely the move to domain-based assessment tools)[@sterne2019] and existing methods for bias-/indirectness-adjusted meta-analysis[@turner2009] to integrate the numerical results of the multiple approaches. The absence of any clear signals across the evidence base, as detailed in the previous section, does not make for particularly interesting case studies but I will nonetheless use the identified evidence to illustrate the novel methodological approach. 

&nbsp;<!----------------------------------------------------------------------->  

### Methods

The proposed framework involves several steps, described in detail in the following sections. In summary, these steps are:

1. Define the causal question of interest
1. Identify of relevant evidence sources and standardise effect directions
1. Specify idealised version of each study
1. Assess the extent and direction of bias/indirectness in each result
1. Define modifying terms for bias and indirectness in each result
1. Calculate bias-/indirectness-adjusted results and perform meta-analysis

In order to illustrate the bias-/indirectness adjustment process detailed in the subsequent sections, the process for calculating the adjusted estimate is described in detail for a single result. Following this, the framework is applied to two case studies, as defined below.

&nbsp;<!----------------------------------------------------------------------->  

#### Definition of the causal questions of interest (case-studies)

Using the ROBINS-E framework,[@morganr2020] I defined the parameters of my causal questions of interest:

_Case study #1: Effect of mid-life LDL-c on Alzheimer's disease_

*	_Population of interest_: General population
*	_Exposure of interest_: Low density lipoprotein cholesterol
*	_Exposure window of interest_: Mid-life (45-60)
* _Summary measure of exposure over time_: Average exposure 
* _Outcome of interest:_ Alzheimer's disease

_Case study #2: Effect of mid-life triglycerides on vascular dementia_

*	_Population of interest_: General population
*	_Exposure of interest_: Triglycerides
*	_Exposure window of interest_: Mid-life (45-60)
* _Summary measure of exposure over time_: Average exposure
* _Outcome of interest:_ Vascular dementia

<!-- QUESTION Should population here include a geographical aspect, as in the Discussion I say that the generalisability to other populations is an issue. -->


&nbsp;

These causal questions were chosen for several reasons. Firstly, work presented in previous chapters had identified some evidence for an association in these exposure/outcome pairs. Secondly, given the long prodomal period between the onset of physiological changes in the brain and presentation of dementia symptoms, it seems likely that conditions during the mid-life period are particularly important. Finally, examining the causal impact of a lipid faction on a specific outcome (e.g. Alzheimer's disease), rather than a composite outcome (e.g. all-cause dementia), focuses on an single causal pathway rather than including several conditions in the outcome definition that likely have very different mechanisms of disease. In addition, previous work presented in this thesis illustrated that the component conditions (in this case Alzheimer's disease and vascular dementia) are likely to be subject to very different confounding structures (see Section \@ref(cprd-confounding-by-ind)), and use of an composite all-cause outcome in the triangulation framework may mask this.

&nbsp;<!----------------------------------------------------------------------->  

####	Identify relevant results

Once the causal question of interest had been defined, relevant individual results were obtained from the data sources described in Section \@ref(tri-data-sources). In a broad sense, this meant extracting results that examined the relationship between the exposure/outcome pair, either directly (e.g. non-randomised studies of LDL-c levels) or indirectly (e.g. non-randomised studies of statins, or Mendelian randomisation studies using genetic instruments for LDL-c levels).

Once the set of relevant results were identified, effects were standardised to refer to the risk resulting from a "reduction" in the lipid fraction. For both non-randomised studies and Mendelian randomisation analysis of lipid levels, the association is usually reported per 1-SD increase in the lipid fraction. In this case, the effect estimates were inverted to ensure consistency across study designs.

<!-- TODO Note that the results are converted to the log scale. -->

&nbsp;<!----------------------------------------------------------------------->  

#### Specify idealised version of each study

Once the set of relevant results have been identified, an idealised study for each is described
An idealised study can be viewed as a replicate of the study producing the result of interest but with all sources of bias removed. The risk of bias is then assessed against this idealised study, while the causal question addressed by each idealised study is compared with the target causal question to define the indirectness of each result. 

Note that all of the risk-of-bias tools used to assess non-randomised studies required specification of an idealised version of the study, against which bias was assessed. If using a risk-of-bias assessment tool that does not require this step, the idealised version of the study should be defined in advance of risk-of-bias assessment.

&nbsp;<!----------------------------------------------------------------------->  

####	Assess risk and direction of bias in each result

The assessment of bias in each result is discussed in Section \@ref(tri-data-sources) above.For the sake of consistency and ease of computing, I mapped the different acceptable risk-of-bias judgements in each tool to a harmonised set: "Low", "Moderate", and "High". The exact mapping can be seen in Table \@ref(tab:robLevelsMapping-table). Of note, no mapping was performed for the critical risk-of-bias levels present in the tools for non-randomised studies. This is because current best practice in evidence synthesis is to exclude all studies at critical risk of bias for further quantitative synthesis.[@sterne2016]

&nbsp;<!----------------------------------------------------------------------->  
(ref:robLevelsMapping-caption) Mapping of the different acceptable levels of bias across the assessment tools to a harmonised set. Note that no mapping for "Critical" risk of bias was performed, as best practice reccommends that studies at critical risk of bias are excluded from quantitative syntheses.

(ref:robLevelsMapping-scaption) Mapping of risk-of-bias judgements across assessment tools

```{r robLevelsMapping-table, message=FALSE, results="asis", echo = FALSE}
```
&nbsp;<!----------------------------------------------------------------------->  

In addition to assessing the extent of bias, as defined by the three levels detailed above, I attempted to record the predicted direction and type of bias in each domain. This was achieved via an additional question at the end of each bias domain, which asked assessors to predict the expected direction of bias in that domain. Note that this question is currently only formally included in two existing tools (ROB2/ROBINS-I), but I employed an identical approach during assessment of non-randomised studies of exposure and Mendelian randomisation studies. Acceptable responses to this question included: 

<!-- REVIEW in fact it is a mandatory part of new ROBINS-E tool, while only optional in RoB2 and ROBINS-I. Maybe reiterate that using a very early version of ROBINS-E -->


* "Favours experimental"/"Favours comparator" (defines an additive bias)
* "Towards null"/"Away from null" (defines a proportional bias)
* "Unpredictable"

As indicated in the options above, the response to this question is also used to determine the predicted type of bias as either additive or proportional. Proportional biases are dependent on the magnitude of the effect, while additive biases are not.[@turner2009]

<!-- TODO Need to include some text here on examples of each: e.g. immortal time bias, or  -->


For additive biases, determining the absolute direction of bias was simply a case of whether the bias is expected to shift the effect estimate to the left or right on an imaginary forest plot. For example, the estimate would be shifted to the right if a bias was predicted to favour the comparator (Figure \@ref(fig:exampleDirection)). 

In contrast, for proportional biases, whether the estimate should be increased or decreased proportionally depends on the current position of the point estimate relative to the null. For example, if the effect estimate represents a protective effect (below the null), then bias towards the null would be adjusted for by moving the effect estimate proportionally to the right. In contrast, if the effect of the intervention is harmful (effect estimate above the null), bias towards the null would be adjusted for by moving the effect estimate proportionally to the left. Both scenarios are illustrated using example data in Figure \@ref(fig:exampleDirection).

<!----------------------------------------------------------------------------->
 ```{r exampleDirectionSetup, include = F}
 ```
 
(ref:exampleDirection-cap) Illustration of calculating the absolute direction of biases (indicated by arrows), based on bias type. For additive biases, the direction is consistent regardless of the position of the effect estimate relative to the null - bias "favouring the comparator" will always pull the effect estimate to the right, and can induce a change from a protective to harmful effect. In contrast, the position of the effect estimate is accounted for when determining the absolute direction of proportional biases, defined as towards or away from the null. 

(ref:exampleDirection-scap) Illustration of calculating the absolute direction of biases, based on bias type.

```{r exampleDirection, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:exampleDirection-cap)', out.width='100%', fig.scap='(ref:exampleDirection-scap)'}

knitr::include_graphics(file.path("figures/tri/exampleDirection.png"))

```
<!----------------------------------------------------------------------------->

The predicted direction and type of bias were not recorded for domains at "Low" risk of bias. Finally, for some domains, only one type of bias is allowed. For example, in the confounding domains in the ROBINS-I/ROBINS-E tools, only the "Favours experimental"/"Favours comparator" and "Unpredictable" options are available, meaning that bias in this domain will always be considered additive.

&nbsp;<!----------------------------------------------------------------------->  

#### Visualisation of extent and direction of bias

To aid with the quantitative triangulation exercise, I created a new method to visualise the extent, direction and type of bias in each result, enabling detailed comparison across different studies contributing to a synthesis. Similar to the standard paired forest plots introduced in Chapter \@ref(sys-rev-), these "bias direction" plots show the level (or extent) of bias across the domains for each result reported using coloured blocks. However, in contrast to the previous forest plots, symbols are used to illustrate the predicted absolute direction of bias in that domain. Distinct symbol pairs are used to denote additive and proportional biases. Illustrations of these are provided in the Section \@ref(quant-tri-results).

&nbsp;<!----------------------------------------------------------------------->  

####	Assign modifying values to risk/direction of bias
<!-- TODO Note that they are on the log scale, and that this requires the results to be on the log scale too! - Lines 45-50 of addbias -->

Following definition of the extent, type and direction of bias in each domain, I assigned a prior distribution on the log scale to each combination. For example, a "high" additive bias in $j$th domain of the $i$th study is defined as $\delta_{i,j}^{\mathrm{High}}$ and uncertainty around this estimate is given by a distribution:

\begin{equation}
  \delta_{i,j}^{\mathrm{High}} = f(\mu_{i,j}^{\mathrm{High}}, \sigma_{i,j}^{\mathrm{High}})
  (\#eq:name)
\end{equation}

The sign of $\mu_{i,j}^{\mathrm{High}}$ is defined by the absolute direction of the bias. If the bias is expected to pull the effect to the left, $\mu_{i,j}^{\mathrm{High}}$ is given a negative sign, and if it is expected to pull the effect to the right, it is given a positive sign.

<!-- QUESTION sign is negative if to the left, because you are taking it away in the final formula and it therefore needs a negative sign to be positive overall! -->

<!-- TODO Need to explain here that for proportional bias, the results are exponentiated  -->

One key feature of the domain-based risk-of-bias tools is that the domains are considered interchangeable - i.e. a "high" judgement in one domain is equivalent to a "high" judgement in any other. As such, for this analysis, I assumed that the distributions assigned to each extent of bias were identical across all values of $j$, that is, were identical for all domains in the risk-of-bias assessment tool. To illustrate for additive biases:

$$
\delta_{i,1}^{\mathrm{High}} = \delta_{i,2}^{\mathrm{High}} = ... = \delta_{i,j}^{\mathrm{High}}
$$

and similarly

$$
\delta_{i,1}^{\mathrm{Moderate}} = \delta_{i,2}^{\mathrm{Moderate}} = ... = \delta_{i,j}^{\mathrm{Moderate}}
$$

Reasonable values for the position and spread of the prior distributions were informed by a previously-reported expert bias elicitation exercise.[@turner2009] Using open data from that study, I calculated the mean values for the mean and variance of the adjustment distributions across all biases considered by that exercise (see Appendix \@ref(appendix-adjustment-values) for more details on how these were calculated). For the purposes of this illustrative analysis and to highlight the generalised nature of the code used to perform the analysis (see Section \@ref(tri-software)), I used the calculated values to inform two scenarios of modifying distributions (Table \@ref(tab:priorsAdd-table)) for additive biases, and a single set for proportional biases. In the first scenario, the relationship between the position assigned to each additive judgement is linear. In the second scenario, the step from "Moderate" to "High" is twice that from "Low" to "Moderate". Across both additive and proportional biases, the variance of the "High" judgement distribution was defined to be greater than that of the "Moderate" judgement.

&nbsp;<!----------------------------------------------------------------------->  

(ref:priorsAdd-caption) Prior distributions for extent and type of bias under two scenarios, on the log scale. Note that the distributions for proportional biases were kept consistent across the two scenarios.

(ref:priorsAdd-scaption) Prior distributions mapped to different extents of bias.

```{r priorsAdd-table, message=FALSE, results="asis", echo = FALSE}
```

&nbsp;<!----------------------------------------------------------------------->  

<!-- TODO In the absence of any empirical data regarding the priors, I used the data from the expert elicitation approach to calculate both the mean and max. These estimates, in addition to conversations with topic experts -->

 <!-- TODO Link this to open data! -->

Where the direction of bias in a domain was unpredictable for a given result, the mean of the prior distribution for that domain was set to 0 but the appropriate variance for the recorded extent of bias was retained (e.g. for an unpredictable "High" additive bias, the distribution would be $N(0,0.1)$ under Scenario 1). In other words, adjusting for bias in a domain with an unpredictable direction of bias has no impact on the position of the effect estimate but does increase the uncertainty around it.

&nbsp;<!----------------------------------------------------------------------->  

####	Assessing and assigning prior values to indirectness

The indirectness of a result (also termed external bias, external validity, relevance, generalisability, or applicability) is defined here as the discrepancy between the research question addressed by the "idealised" study and the causal question of interest.

An identical approach was employed to assess, and assign prior distributions to, the indirectness in each result. The target question for each result was compared against the causal question of interest with respect to three domains, defined as important by the GRADE framework for assessing the certainty of evidence:[@guyatt2011] population, intervention/exposure, and outcome. I again used the scale of "Low/"Moderate"/"High" to quantify the extent of indirectness in each domain. All indirectness was defined _a priori_ as being proportional in nature (i.e. depending on the magnitude of the effect), in line with previous work on this topic.[@turner2009;@thompson2011] As above, data from the previous elicitation exercise were used to inform reasonable prior distributions for each level of indirectness (Table \@ref(tab:priorsIndirect-table)).

&nbsp;

<!----------------------------------------------------------------------------->
(ref:priorsIndirect-caption) Prior distributions for extent of indirectness, on the log scale.

(ref:priorsIndirect-scaption) Prior distributions mapped to different extents of indirectness.

```{r priorsIndirect-table, message=FALSE, results="asis", echo = FALSE}
```
<!----------------------------------------------------------------------------->

&nbsp;

As an illustrative example, consider the first causal question of the interest in this exercise, the effect of LDL-c in mid-life on Alzheimer's disease. Here, studies of lipids levels in this time period would require minimal adjustment, whereas studies examining statin use (indirect exposure/intervention) in late-life (indirect population) would be adjusted and down-weighted due to reduced relevance to the causal question.

&nbsp;<!----------------------------------------------------------------------->  

####	Combine in a bias-adjusted meta-analysis 

Using the the method reported in Turner _et al._,[@turner2009] total additive and proportional bias and indirectness were calculated and used to define an adjusted estimate for each result included in the synthesis. 

The adjusted estimate for each result, $\hat\theta$, is defined as:

<!-- TODO Need to be able to explain the order in which the biases are adjusted for -->

<!-- TODO Talk about validation at some point -->


\begin{equation}
  \hat{\theta} = \frac{y_i - \mu_{i\beta}^{\mathrm{In}}\mu_{i\delta}^{\mathrm{In}} - \mu_{i\delta}^{\mathrm{B}}}{\mu_{i\beta}^{\mathrm{B}}\mu_{i\beta}^{\mathrm{In}}}
  (\#eq:adjusted-mean)
\end{equation}

where $\mu_{i\delta}^{\mathrm{B}}$ and $\mu_{i\beta}^{\mathrm{B}}$ refer to the total additive and proportional bias, and  $\mu_{i\delta}^{\mathrm{In}}$ and $\mu_{i\beta}^{\mathrm{In}}$  refer to the total additive and proportional indirectness. Note that in this exercise, the total additive indirectness $\mu_{i\beta}^{\mathrm{In}} = 1$, as all indirectness was defined _a priori_ as being proportional.

The standard error of this estimate is then calculated as:

\begin{equation}
  \mathrm{SE}(\hat{\theta})=\left(\frac{1}{\mu_{i \beta}^{\mathrm{B}} \mu_{i \beta}^{\mathrm{In}}}\right)^{2}\left(s_{i}^{2}+\left(\mu_{i \beta}^{\mathrm{B}} 2+\sigma_{i \beta}^{\mathrm{B}}\right)\left(\hat{\theta}^{2} \sigma_{i \beta}^{\mathrm{In} 2}+\sigma_{i \delta}^{\mathrm{In} 2}\right)+\sigma_{i \beta}^{\mathrm{B}}\left(\hat{\theta} \mu_{i \beta}^{\mathrm{In}}+\mu_{i \delta}^{\mathrm{In}}\right)^{2}+\sigma_{i \delta}^{\mathrm{B} 2}\right)
  (\#eq:adjusted-se)
\end{equation}

Once each individual result had been adjusted using this approach, I performed a random effects meta-analysis using the unadjusted and adjusted results. I also compared the adjusted results under the two scenarios of additive bias defined. results. I extracted the overall effect estimates, along with measures of heterogeneity in each case ($\tau^2$, $I^2$).[@higgins2003; @higgins2008]

<!-- TODO Should a fixed or random effects be used, because in theory you are adjusting for all potential causes of heterogeneity. -->

<!-- TODO Sensitivity analysis using only heterogeneity - no change to point estimate - places less importance on the accurate determination of the direction of bias -->



&nbsp;<!----------------------------------------------------------------------->  

### Results {#quant-tri-results}

```{r ldlAdBIAMA, include = F}
```

```{r tgVadBIAMA, include = F}
```

#### Single study

As an illustrative example of the process using a single result, the bias and indirectness inherent to the estimate of the effect of statin use on Alzheimer's disease in the CPRD (as analysed in Chapter \@ref(cprd-analysis-heading)) are considered here. For this result, there were three domains at greater than low risk of bias: Bias due to confounding, Bias due to definition of the outcome, and Bias in the selection of the reported result (Figure \@ref(fig:biasDirectionSingle)). In Domain 1 (bias due to confounding), the study did not adjust for _ApoE4_ status, which is predicted to mask any true association between statins and Alzheimer's disease (see Section \@ref(cprd-limitations) for a fuller discussion). As such, the bias is predicted to _favour the comparator_ and so the absolute direction of bias is to the right. In Domain 7 (bias in measurement of the outcome), there was a high risk of differential misclassification on the basis of the exposure. Here, history of statin use may make a diagnosis of vascular dementia more likely than Alzheimer's disease, and so for this outcome, this bias is predicted to _favour the experimental_ (in this case, an intervention). As such, the absolute direction of bias is to the left. In Domain 7 (bias in selection of the reported result), for consistency with the other NRSI, in the absence of a protocol the bias is assumed to be _away from the null_. Given the position of the effect estimate below the null, the absolute direction of bias in this domain is to the left.

&nbsp;<!----------------------------------------------------------------------->  
(ref:biasDirectionSingle-cap) Bias direction plot for a single study showing the predicted direction of bias in each domain. Additive biases are characterised using arrows, while the proportional biases are denoted using $<$ and $>$. A question mark indicates that the direction of bias was unpredictable.

(ref:biasDirectionSingle-scap) Bias direction plot for a single study
```{r biasDirectionSingle, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:biasDirectionSingle-cap)', out.width='100%', fig.scap='(ref:biasDirectionSingle-scap)'}
knitr::include_graphics(file.path("figures/tri/midlife_AD_single.png"))
```
&nbsp;<!----------------------------------------------------------------------->  

Indirectness was intentionally not displayed in the plot above, as these figures are created using `robvis` which is focused on creating visualisations of risk-of-bias data. In addition, I found it more useful to articulate the indirectness of a result in tabular format. With respect to this example result, I judged it to be a low risk in the population and outcome domains (Table \@ref(tab:singleIndirect-table)). However, the result refers to the effect of statins on Alzheimer's disease risk, rather than LDL-c levels directly, putting it at high risk of indirectness in the intervention/exposure domain. Assessing the predicted direction of indirectness was more challenging than assessing the predicted direction of bias. In this case, treatment with statins result in temporary lowering of lipid levels which and could thus underestimate the true effect of LDL-c lowering (indirectness towards the null). In contrast, statins may have an effect on Alzheimer's disease through a mechanism other than LDL-c lowering effect of statins and so the effect is overestimated (indirectness away from null). As such, I judged the direction of indirectness in this domain to be unpredictable.

<!-- TODO Consider timing of outcome as an issue - but is this a relevance or bias issue -->

&nbsp;<!----------------------------------------------------------------------->  
(ref:singleIndirect-caption) Assessment of indirectness for a single example study.

(ref:singleIndirect-scaption) singleIndirect

```{r singleIndirect-table, message=FALSE, results="asis", echo = FALSE}
```
&nbsp;<!----------------------------------------------------------------------->  

The unadjusted estimate was `r single_unadjusted `. After accounting for the biases and indirectness described, the adjusted result was `r single_adjusted `.

&nbsp;<!----------------------------------------------------------------------->  

#### Case study #1: effect of LDL-c at midlife on Alzheimer's disease

From the data sources identified in Section \@ref(tri-data-sources), I identified 18 results relevant to my first causal question of interest. Most (n=17) were identified via the systematic review,`r ldl_ad_citations` while Chapter \@ref(cprd-heading) provided an additional estimate from the CPRD analysis.  The extent, type and direction of predicted bias for each result can be seen in the bias-direction plot presented in Figure \@ref(fig:ldlAdBiasDirection), stratified by study design.

<!-- QUESTION Hypercholesterolemia should not be included here, as it is focused on total cholesterol rather than specifically LDL-c, right? -->  

&nbsp;<!----------------------------------------------------------------------->  

(ref:ldlAdBiasDirection-cap) Bias direction plot, summarising the internal biases related to effect of LDL-c on Alzheimer's disease, stratified by study design.

(ref:ldlAdBiasDirection-scap) Bias direction plot, summarising internal biases

```{r ldlAdBiasDirection, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:ldlAdBiasDirection-cap)', out.width='100%', fig.scap='(ref:ldlAdBiasDirection-scap)'}
knitr::include_graphics(file.path("figures/tri/midlife_AD.png"))
```
<!-- TODO Bias direction plot is not producing subgroup test for some reason -->

&nbsp;<!----------------------------------------------------------------------->  

The results of the unadjusted and the bias-/indirectness-adjusted (under Scenario 1) are shown in Figure \@ref(fig:fpLdlAd). Following adjustment for bias and indirectness, the observed effect attenuates to the null (unadjusted `r unadj_effect`; adjusted `r adj_effect_scenario1`). Additionally, adjustment for bias and indirectness substantially reduced the heterogeneity between studies (unadjusted $\tau^2$ = `r unadj_tau2`, $I^2$ = `r unadj_I2`; adjusted  $\tau^2$ = `r adj_tau2`, $I^2$ = `r adj_I2`). However, as can been seen from the right panel in Figure \@ref(fig:fpLdlAd), this reduction in heterogeneity between studies is largely achieved via a reduction in the precision of each individual result.

<!-- TODO How effect are fibrates at lowering triglycerides? is it a direct effect, or are there alternative -->

&nbsp;<!----------------------------------------------------------------------->  

<!-- TODO This should really be stratified by type -->

(ref:fpLdlAd-cap) Random effects meta-analysis of the association of midlife LDL-c with Alzheimer's disease, using unadjusted and bias-/indirectness-adjusted results.

(ref:fpLdlAd-scap) Random effects meta-analysis using unadjusted and bias-/indirectness-adjusted results.

```{r fpLdlAd, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:fpLdlAd-cap)', out.width='100%', fig.scap='(ref:fpLdlAd-scap)'}
knitr::include_graphics(file.path("figures/tri/fp_paired_midlife_ldl_ad.png"))
```

&nbsp;<!----------------------------------------------------------------------->  

No substantial differences were observed between the summary estimates obtained under the two scenarios of additive bias (Appendix \@ref(appendix-tri-analysis)).

<!-- TODO Need to present overall summary estimate under two scenarios of bias and then send people to the Appendix. -->

&nbsp;<!----------------------------------------------------------------------->  

#### Case study #2: effect of triglycerides at midlife on vascular dementia

From the data sources identified in Section \@ref(tri-data-sources), I identified 7 results relevant to my causal question of interest: 4 were identified via the systematic review,`r tg_vad_citations` while Chapter \@ref(cprd-heading) provided two additional estimates from unanalysed datasets (CaPS and Whitehall II), and Chapter \@ref(ipd-heading) provides an estimate for the effect of fibrates, a treatment for hypertriglyceridaemia. The extent, type and direction of predicted bias for each result can be seen in the bias-direction plot presented in Figure \@ref(fig:tgVadBiasDirection), stratified by study design.

<!----------------------------------------------------------------------------->
(ref:tgVadBiasDirection-cap) Bias direction plot, summarising the internal biases related to effect of triglycerides on vascular dementia, stratified by study design.

(ref:tgVadBiasDirection-scap) shortcap

```{r tgVadBiasDirection, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:tgVadBiasDirection-cap)', out.width='100%', fig.scap='(ref:tgVadBiasDirection-scap)'}
knitr::include_graphics(file.path("figures/tri/midlife_VaD.png"))
```
<!----------------------------------------------------------------------------->

Comparison of the unadjusted and bias-/indirectness-adjusted results for the effect of triglycerides on vascular dementia did not demonstrate a substantial difference (unadjusted `r unadj_effect_vad`; adjusted `r adj_effect_scenario1_vad`; Figure \@ref(fig:fpTgVad)), though again, heterogeneity between the adjusted results was greatly reduced (unadjusted $\tau^2$ = `r unadj_vad_tau2`, $I^2$ = `r unadj_vad_I2`; adjusted  $\tau^2$ = `r adj_vad_tau2`, $I^2$ = `r adj_vad_I2`). Similarly there was minimal difference between the results under the two scenarios of bias (Figure \@ref(fig:fpTgVaDComparison) in Appendix \@ref(appendix-tri-analysis)).

<!-- TODO Need to present overall summary estimate under two scenarios of bias and then send people to the Appendix. -->

<!----------------------------------------------------------------------------->
(ref:fpTgVad-cap) Random effects meta-analysis of the association of midlife triglycerides and vascular dementia, using unadjusted and bias-/indirectness-adjusted (Scenario 1) results.

(ref:fpTgVad-scap) shortcap

```{r fpTgVad, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:fpTgVad-cap)', out.width='100%', fig.scap='(ref:fpTgVad-scap)'}
knitr::include_graphics(file.path("figures/tri/fp_paired_midlife_tg_vad.png"))
```

&nbsp;<!----------------------------------------------------------------------->  

## Discussion

### Summary of findings

This chapter has narratively synthesised the evidence identified and produced by the previous chapters, highlighting the absence of any consistent association between any blood lipid and any dementia outcome.

In addition, it has sought to provide a generalised framework for quantitative triangulation, building on existing methods for systematic domain-based risk of bias assessment and bias-/indirectness-adjusted meta-analysis. To illustrate the method, I considered two causal questions: the effect of LDL-c at mid-life with Alzheimer's disease and the effect of triglycerides on vascular dementia. In the quantitative triangulation framework, there was weak evidence for an effect in relation to either of the causal questions considered. The heterogeneity between results produced by different study designs contributing to the analysis was substantially reduced using this method, though this was largely due to a reduction in the precision of each individual result. 

&nbsp;<!----------------------------------------------------------------------->  

###	Limitations

<!-- TODO Data-driven hypothesis testing - only choosing those the two strata that have some suggestion of an effect -->

The quantitative analysis presented in this chapter is subject to some strong methodological limitation, which are discussed in detail below.

&nbsp;<!----------------------------------------------------------------------->  

#### Defining reasonable prior distributions for bias and indirectness {#tri-prior-def}

The key limitation of the quantitative synthesis presented in this chapter is the lack of empirical evidence available for the prior distributions for bias and indirectness. While I attempted to address this by informing the prior distributions using data from a previous expert elicitation exercise, the extent of bias/indirectness in that analysis may not generalise to the one presented here.

Ideally, these prior distributions would be based on empirical data on the effect of different domains of bias/indirectness on a result. Most meta-epidemiological studies examining the effect of different methodological issues studied only randomised controlled trials,[@amer2021; @page2016] and the estimates of bias they produce may not hold for non-randomised study designs. However, the prior distributions defined here are broadly comparable to previously reported estimates of the impact of bias in non-randomised trials. For example, a previous simulation study estimated that, in the absence of true effect of LDL-c, _ApoE4_ would induce a RR of 1.09 with risk of dementia per 1-SD increase in LDL-c.[@iwagami2021] This is comparable to the mean assigned to the prior distribution mapped to "Moderate" additive bias (N(0.08,0.05), Table \@ref(tab:priorsAdd-table)).

<!-- TODO Also mention here that when the number of results is large, performing elictation for each separately in addition to the risk of bias assessments is going to be difficult. -->

A further limitation is the assumption that the distributions of bias are identical across domains of bias. Previous evidence from meta-epidemiological studies of randomised controlled trials that investigated the effects of different biases indicates that this is unlikely to be the case.[@savovic2018] The generalised framework for quantitative triangulation, presented here and available via the `triangulate` package (see Section \@ref(tri-software)), allows for domain-specific distributions of bias/indirectness. As more information on the effect of specific sources of bias becomes available, such domain-specific distributions should be used. 

Finally, it may in fact be more reasonable for domains such as bias due to confounding to adjust on a per-confounder basis rather than mapping to a "Moderate" or "High" extent of bias. In this approach, prior distributions are assigned to each of the confounders pre-specified as part of the ROBINS-I/ROBINS-E tools.[@sterne2016] Then, rather than assigning a domain level distribution based on an arbitrary judgement of how many important confounders are missing, the result is adjusted for each confounder not accounted for in the original analysis.

&nbsp;<!----------------------------------------------------------------------->  

#### Accuracy of bias-/indirectness-assessment {#tri-accuracy}

A key issue in this analysis is the accuracy of the assessment of bias and indirectness in each result. It has been widely demonstrated that the inter-rater agreement when using risk-of-bias tools is low with regards to the extent of bias assigned to each domain[@hartling2011; @minozzi2019; @minozzi2020] Though not previously studied, given the difficulty in assessing the predicted direction of bias, agreement on this aspect of the tools is likely to be lower still.

A further issue in this regard is that the rigour of the tools may not be equivalent. This issue can be illustrated by the Ostergaard _et al._ study[@ostergaard2015] having low risk of bias across all domains and thus receiving a substantial proportion of the weight in the first case study (Figure \@ref(fig:fpLdlAd)). While the RoB suite of tools (RoB 2.0, ROBINS-I, ROBINS-E) were developed by an expert working group and have been widely used, the Mamluk _et al._ tool[@mamluk2020] used to assess risk of bias in Mendelian randomisation studies was designed by the authors for use in their own review. If the Mamluk tool is failing to adequately assess bias in Mendelian randomisation studies, then any analysis based on its assessments is likely to be subject to bias. This observation is particularly problematic given the default position of the ROBINS-I and ROBINS-E tool to require a "Moderate" judgement in the confounding domain. Under these conditions, it is possible that a well-performed cohort study (low risk of bias across everything other that bias due to confounding) will be down-weighted versus a potentially poor MR study.

&nbsp;<!----------------------------------------------------------------------->  

#### Low and critical risk of bias

As illustrated in Table \@ref(tab:robLevelsMapping-table), studies at critical risk of bias were not included in the analysis. While this is in line with best practice, there is theoretically no reason why studies with this extent of bias could not be included in the propsed framework. However, the estimation of an appropriate prior distribution for the effect of "Critical" bias would be substantially more challenging, and so was avoided here.

A related issue is the "Low" risk of bias judgement. In this analysis, I assumed that domains at "Low" risk of bias did not require any adjustment. However, "Low" risk of bias is not equivalent to the absence of bias, and potentially should still be adjusted for, if only minimally. In this case, defining the predicted direction of bias would be particularly challenging in the absence of obvious sources of bias. 

&nbsp;<!----------------------------------------------------------------------->  

#### Combination of different effect measures

A final limitation to this analysis is the synthesis of different effect estimates. As discussed in Section \@ref(sys-rev-analysis-overview), hazard ratios are not directly comparable to odds ratios, as they inherently account for person time-at-risk.[@mckenzie2019] As non-randomised studies (NRSI/NRSI) of dementia outcomes report hazard ratios and Mendelian randomisation studies report odds ratios, the resulting synthesis may be biased by the integration of these two different effect measures. This is primarily a concern for common outcomes, as when the outcome is rare, the odds, risk and hazard ratios approximate each other.

<!-- REVIEW Could add that ORs could be converted to RRs using a measure of "hyptothecial" risk -->

<!-- TODO An extra step of the process should be the consideration of whether it is reasonable to synthesis across different effect estimates. Fine for rare, not for common. Fancy models that can be used to synthesis effect estimates are still compatabile with this approach as each invidual estimate is first adjusted and the adjusted estimate can then be used with whatever meta-anlaysis technique you like. -->

&nbsp;<!----------------------------------------------------------------------->  

### Strengths

The core strength of this analysis is that it is based on a comprehensive systematic review, supplemented by two additional primary studies to fill in the identified evidence gaps. In general, triangulation of any sort should be considered a natural extension of evidence synthesis, and therefore should follow best practice in relation to finding and critically assessing all relevant information. Additionally, the approach presented here also builds on recent developments in bias assessment to "explode out" the component results of a meta-analysis, and consider the effects of bias/indirectness in each separately. 

A further advantage of this method comes from the ability to specify the prior distributions for each level of bias/indirectness in advance of performing the assessments. Expert elicitation of the extent of bias/indirectness using a panel of methodologists and topic experts is a powerful technique but the point at which it is deployed in the framework is important. In previous attempts at bias-/indirectness-adjusted meta-analysis, the extent of bias in each study was assessed via a elicitation process,[@thompson2011; @turner2009; @wilks2011] during which experts were aware of the results of each analysis. This approach is potentially subject to differential misclassification of the impact of bias/indirectness on the basis of the results, as there is no way to ensure that results at a similar level of bias for confounding (for example) are being adjusted by the same amount across studies. As an illustrative example, if experts are influenced by the knowledge of the effect estimate in a study, then a result at "Moderate" risk of confounding and demonstrating a stronger protective effect may receive greater adjustment than a study at the same risk of confounding but with a more modest effect. This is likely to be particularly problematic where experts have preconceived ideas about the true effectiveness of the intervention. 

Separating the assessment of bias/indirectness from the assignment of modifying values to each judgement will limit the potential for this misclassification. Using the framework proposed, reasonable modifying distributions for each level of bias can be defined _a priori_ by the study team using the elicitation procedure detailed previously,[@turner2009] similar to how important confounders and co-interventions are defined in advance when performing ROBINS-I/ROBINS-E assessments.[@sterne2016] As an example, expert elicitation could be used to _a priori_ define an additive bias distribution of N(.1,0.7) for "Moderate" risk of bias in Domain 1 of the ROBINS-I tool (bias due to confounding). Risk-of-bias assessments are then performed, and each result at "Moderate" risk of bias in Domain 1 is adjusted using this pre-specified distribution.

Finally, accounting for bias using an incorrect prior distribution is no less problematic that synthesising and drawing conclusions from effect estimates as if they were unbiased, a common occurrence in systematic reviews.[@katikireddi2015] While this analysis may be limited by the absence of empirically-derived adjustment distributions, it at the very least acknowledges the uncertainty of evidence due to bias/indirectness via a reduction in precision. 

&nbsp;<!----------------------------------------------------------------------->  

### Future research

<!-- REVIEW Good to mention direct adjustment for bias, e.g. Greenlands writings -->

An obvious avenue for future work in relation to quantitative triangulation is the identification of empirical prior distributions for the effect of bias/indirectness in non-randomised studies using meta-epidemiological approaches. This will be substantially more challenging than examining the effect of bias in RCTs,[@savovic2018] given the absence of an underlying database of meta-analysis of non-randomised studies.

Future development of this framework should also account for bias at the analysis level in terms of missing evidence.[@zotero-15123] For example, there is at least one known study relevant to the vascular dementia case study that reported a non-significant result but provided insufficient details to be included in the analysis.[@chiang2007] Ideally, a quantitative triangulation framework would further account for this proportional meta-bias (as bias due to missing evidence is most likely to bias away from the null due to publication bias mechanisms), in addition to result-specific biases.

Appreciation that both the risk-of-bias and indirectness of a result should be assessed is growing. Indeed, some existing for the assessment of diagnostic test accuracy[@whiting2011] and prediction models[@moons2019] consider indirectness (termed applicability in these tools) alongside the assessment of bias. Future iterations of the core risk-of-bias tools (RoB 2, ROBINS-I, ROBINS-E) could take this into account, though there is an competing argument that indirectness is already handled via tools such as the GRADE framework.[@guyatt2011] In addition, simple steps like harmonising the risk-of-bias judgements across tools and making the direction of bias question mandatory (even if users default to "Unpredictable") would represent an improvement in the tools and encourage users to think about how the biases assessed affect the corresponding result. Similarly, software that implements a risk-of-bias tool should allow for direction/extent of bias question and carefully consider how this data will be exported.

&nbsp;<!----------------------------------------------------------------------->  

### Outputs {#tri-software}

There are two key outputs from this project. The first is the `triangulate` R package. Personal communication with the authors of the original method resulted in the STATA code to implement the bias-/indirectness-adjusted model.[@turner2009] This has since been generalised as part of the `triangulate` R package to enable other users to apply the approach detailed here. The package allows for preprocessing of domain-based risk-of-bias data to correctly identify the direction of the bias relative to the effect estimate, use of domain-specific prior distributions, production of bias direction plots (via the tool described in Appendix \@ref(appendix-robvis), calculation of bias/indirectness-adjusted estimates for each result, and synthesis of these adjusted results in a standard random-effects meta-analysis.

The second key output is an annotated example dataset for the LDL-c/Alzheimer's disease causal question addressed in this chapter. Available via the `triangulate` package, this data will provide developers of new triangulation methods with an example dataset on which to test new tools, something which seriously hindered development of this work.

&nbsp;<!----------------------------------------------------------------------->  

## Summary

* In this chapter, I narratively described the evidence identified or produced in previous chapters, and highlighted the issues with a qualitative approach to triangulation when there are several sources of evidence.

* I then illustrated a proposed generalised framework for quantitative triangulation, exploiting existing methods in evidence synthesis and recent developments in the assessment of different risks of bias. I illustrated this method using two case studies: the effect of mid-life LDL-c on Alzheimer's disease, and the effect of mid-life triglycerides on vascular dementia.

* I discussed the limitations of this proposed method, given the absence of informative priors for the impact of bias/indirectness, and proposed future research (i.e. meta-epidemiological studies) that would address them.

* In summary, quantitative triangulation is a promising field that should be considered a natural extension of evidence synthesis. The implications of the synthesised evidence presented here to clinical practice, public health and future research is considered in the following chapter.
