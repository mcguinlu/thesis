---
bibliography: bibliography/references.bib
csl: bibliography/nature.csl
output:
  bookdown::pdf_document2:
    template: templates/brief_template.tex
  bookdown::word_document2: 
      toc: false
      toc_depth: 3
      reference_docx: templates/word-styles-reference-01.docx
      number_sections: false 
  bookdown::html_document2: default
documentclass: book
---

```{block type='savequote', include=knitr::is_latex_output(), quote_author='(ref:tri-quote)', echo = TRUE}
Next on my list of features to be specially considered I would place the consistency
of the observed association. Has it been repeatedly observed by different persons, in different places, circumstances and times?
```
(ref:tri-quote) --- Sir Austin Bradford Hill, 1965 [@hill1965]

<!-- TODO Add this to the Chapter summary in the introduction -->

<!-- ### Triangulation  -->

<!-- TODO Have a look at this - potentially move to triangulation chapter -->

<!-- One key question for which multiple distinct sources of evidence were available were those looking at Laz -->

<!-- Consideration of the potential impact of the magnitude and direct of residual confounders/bias is not a major stretch from what is already happening in the assessment of the quality of evidence (GRADE) framework. Within GRADE, the overall quality of evidence can be upgraded when there is deemed to be unmeasured or residual confounding variables which reduce the. For example, if the propensity to treatment is related to comorbidity burden, but those on treatment still have better outcomes then those on control, it is likely that the true effect of the intervention is being underestimated. [@guyatt2011] -->

# Aetiological triangulation across new and existing evidence sources {#tri-heading}

\minitoc <!-- this will include a mini table of contents-->

```{r, echo = FALSE, warning=FALSE, message=FALSE}
source("R/helper.R")
knitr::read_chunk("R/05-Code-CPRD-Analysis.R")
knitr::read_chunk("R/07-Code-Triangulation-Analysis.R")
doc_type <- knitr::opts_knit$get('rmarkdown.pandoc.to') # Info on knitting format
```

## Lay summary

__TBC__

<!-- Triangulation is the practice of using multiple sources of evidence to provide more reliable answers to a research question. Different sources of evidence will have different limitations. If the result from each source points towards the same answer, this improves our confidence in the conclusion. -->

&nbsp;<!----------------------------------------------------------------------->  

\newpage

\newpage

## Introduction {#triangulation-overview}

Aetiological triangulation, or simply triangulation, is the process of comparing and contrasting across different sources of evidence. Triangulation is broadly comparable to Bradford-Hill's criteria of "consistency", that is the replication of an observed relationship across several different contexts,[@hill1965] where contexts are assumed to have different underlying bias structures. More formally it can be defined as: 

> The practice of strengthening causal inferences by integrating results from several different approaches, where each approach has different (and assumed to be largely unrelated) key sources of potential bias.[@lawlor2016]

This approach represents a significant step forward from the current evidence synthesis practice of synthesising evidence from only one approach (e.g. randomised controlled trials (RCTs), non-randomised studies of exposures (NRSE) or interventions (NRSI), etc.). The most common implementation of this method to date has been in the form of _qualitative triangulation_ - that is the identification and a narrative comparison, where the internal biases and differences between the study question and the causal question of interest (indirectness) of each result are discussed.

However, qualitative triangulation faces issues at scale. There is a need to include all evidence, as otherwise the potential for cherry-picking, yet as the number  as it is not possible to compare and contrast across multiple results in any meaningful way. This fact is also illustrated by previous exemplars of triangulation only considering three individual results. <!-- TODO CITATION NEEDED - original triangulation paper and Ference --> An alternative option previously employed is to assign bias to the output of a meta-analysis of similarly designed studies, but this loses information on the specific biases inherent to each results contributing to the summary estimate. For example, while it may be true that all non-randomised studies share some minimal level of bias, investigation of the biases applicable to each individual result gives useful additional information. Recent development in bias assessment have allowed for a much more granular consideration of the threats to the internal validity of a result. In combination, these limitations to qualitative triangulation detail a need for a more systematic way to integrate across multiple evidence sources as the number of individual results contributing to the exercise increases. 

This chapter, in addition to providing a narrative comparison of the existing and new evidence identified in this thesis, builds on recent developments in risk-of-bias assessment and existing methods for bias-/indirectness-adjusted meta-analysis to propose a generalised framework for quantitative triangulation. The method, along with the methodological challenges to its implementation, is illustrated via a proof-of-concept case study examining the causal effect of average exposure to LDL-c at mid-life on Alzheimer's disease risk.  In the following section, I define important terms used throughout this chapter.

&nbsp;<!----------------------------------------------------------------------->  

\newpage

### Terminology {#tri-terminology}

<!-- Discuss and defined three things: -->

<!-- * Qualitative vs quantitative triangulation -->
<!-- * Bias vs. indirectness -->
<!-- * Additive vs proportion effect of bias/indirectness -->

For the sake of clarity, and given the multiple competiting defitions used to define key concepts on this topic, I begin by defining the terms as used in this chapter. 

<!-- TODO Does Julian have a good reference for the conflict between different terms used for biases? -->

__Bias vs indirectness__

Both 

Bias (or internal bias) in the result is defined as systematic deviation from result the "idealised" version of the study (that is, )

In contrast, the indirectness of the result (also called generalisability or applicability) is defined here as the discrepancy between the research question addressed by the "idealised" study and the causal question of interest. Problems with indirectness can be arise from differences in population, intervention/exposure, outcomes and 

Of note, the original method employed in this chapter refers indirectness as "external bias" - however. This distinction is important, as bias and indirectness describe two different issues, and referring to both as bias

In addition, indirectness is the widely used term, including by widely-adopted methods such as the GRADE framework.[@guyatt2011]

__Additive vs proportional effects__


Additive biases (identified by a "Favours experimental"/"Favours comparator" response) are XXXX. A key example of additive bias is immortal time bias, which will always favour the intervention.

Proportional biases (identified by a "Towards null"/"Away from null" response) are those related to the magnitude of the effect. A key example of this type of bias is non-differential misclassification bias, which will bias the effect estimate towards the null.

The effects of both bias and indirectness can be either additive or propotional.

Additive bias/indirectness is

Both bias and indirectness can be defined as additive or propotional. Additive bias/indirectness is that which can shift the p

&nbsp;<!----------------------------------------------------------------------->  

\newpage

## Methods
### Data sources {#tri-data-sources}

This triangulation exercise draws on the research produced in each of the preceding chapters. More specifically, this chapter builds on the comprehensive systematic review presented in chapter \@ref(sys-rev-heading). It also incorporates the new evidence produced by the analysis of the association of statin use with dementia outcomes in the CPRD (Chapter \@ref(cprd-heading)) and of the association of lipids with dementia outcomes in previously unanalysed datasets accesssed via the DPUK (Chapter \@ref(ipd-heading)).

Table \@ref(tab:thesisOverview-table) summarises the research each approach has attempted to address, the exposures and outcomes considered in each study, and the contribution of each chapter to the triangulation exercise presented here.

\blandscape
<!----------------------------------------------------------------------------->
(ref:thesisOverview-caption) Summary of studies included in this thesis, and used as evidence sources in this triangulation exercise. Note, Chapter \@ref(sys-rev-tools-heading) is intentionally not included in this table, as it describes a research tool rather than a research study.

(ref:thesisOverview-scaption) Summary of research designs included in this thesis

```{r thesisOverview-table, message=FALSE, results="asis", echo = FALSE}
```
<!----------------------------------------------------------------------------->
\elandscape


The risk of bias tools used to assess each result are described in detail in Section \@ref(risk-of-bias). In summary, RTCS were assessed using the RoB 2 tool;[@sterne2019] NRSI  using the ROBINS-I tool;[@sterne2016] NRSE using the ROBINS-E tool (see Section \@ref(#rob-tools-nrse));[@morganr2020; @french2019] and MR studies using the Mamluk et al. tool.[@mamluk2020] 

<!-- TODO Talk about how the CPRD and IPD analysis results were assessed here! -->


<!-- Risk of bias assessment was performed for each of the included cohorts using the risk-of-bias assessment tool for non-randomised studies of exposures introduced previously (for a more detailed discussion of this tool, see Section \@ref(rob-tools-nrse)). -->

<!-- Due to the inherent conflict of interest in assessing my own analysis, the result were also assessed by two independent reviewers. -->

&nbsp;<!----------------------------------------------------------------------->  

### Qualitative triangulation

As discussed in the introduction to this Chapter (Section \@ref(triangulation-overview)), as part of a narrative synthesis of the evidence all information sources were grouped by outcome, and systematically compared and contrasted. Potential reasons for heterogeneity between study designs were examined with specific reference to the risk-of-bias assessments performed. 

<!-- TODO Use the fact that it doesn't make sense to qualitatively compare at the single result level to highlight the need for a more quantitative approach - usually default to summary at the -->

<!-- IDEA Note the text by Turner on the fact that you can just adjust for a single type of bias - a good example of this would be to try and adjust for internal biases so you get the best possible estimate and then apply it to something like a assumed life-course model - steal from NIHR text, and refer to the appendix  -->  

This analysis built on the detailed risk of bias assessments performed and presented as part of the systematic review (Chapter \@ref()/\@ref()). Similarly, risk-of-bias assessments were performed for each new source of evidence presented in this thesis, details of which are available in Appendix \@ref(?).

<!-- TODO Need to actually do these, and include results in the analysis. -->

&nbsp;<!----------------------------------------------------------------------->  

### Quantitative triangulation

In addition to the qualitative discussion of evidence, I attempted to integrate the numerical results of the multiple approaches. This proof-of-concept approach incorporates recent advancements in the way that bias in results is assessed (move from checklists to domain-based assessment tools)[@sterne2019] and existing methods for bias-/indirectness-adjusted meta-analysis[@turner2009] to to illustrate how causal questions could be addressed under this quantitative triangulation framework.

This proposed framework involves several steps, as described in detail in the following sections. In summary these steps are:

1. Define the causal question of interest
1. Identify of relevant evidence sources and standardisation of effect directions
1. Assess and visualise the extent and direction of bias in each result
1. Define modifying terms for bias and indirectness in each result
1. Caclulate bias-/indirectness-adjusted results and perform meta-analysis


In order to illustrate the bias-/indirectness adjustment process detailed in the subsequent sections, the process for calculating the adjusted estimate for a single study is described in detail for a single study. <!-- TODO CITATION NEEDED need to cite single paper here --> Following this, the process for an example causal question as a case study, as defined below.

&nbsp;<!----------------------------------------------------------------------->  

#### Definition of the causal questions of interest (case-studies)

Given that this quantitative analysis is intended as a proof-of-concept for the framework, rather than aiming to produce findings that should guide clinical practice, I consider only one of the multiple possible causal questions related to the broad topic of the effect of lipids on dementia outcomes. 

Using the ROBINS-E framework I defined the parameters of my causal question of interest:

*	_Population of interest_: General population
*	_Exposure of interest_: Low density lipoprotein cholesterol
*	_Exposure window of interest_: Mid-life (45-60)
* _Summary measure of exposure over time_: Average exposure

This question was chosen for a number of reason. Firstly, given the long prodomal period between the onset of physiological changes in the brain and presentation of dementia symptoms, it seems likely that conditions during the mid-life period is particularly important. Secondly, examining the causal impact of lipids on a specific outcome (in this case, Alzheimer's disease), rather than a composite outcome (all-cause dementia), focuses on an single causal pathway rather than including conditions that likely have very different mechanisms of disease. Finally, and relevant to its use as a case study for the quantitative triangulation approach, this question had several relevant sources of evidence available (versus, for example, any question looking at vascular dementia).

<!-- TODO This table will describe the causal questions of interest, following the ROBINS-E framework as columns, and list the included studies adn the relative weights of each. -->

&nbsp;<!----------------------------------------------------------------------->  

####	Identify relevant studies

Once the causal question of interest had been defined, relevant individual results were obtained from the data sources described in Section \@ref(tri-data-sources). In a broad sense, this meant pulling out studies that examined the relationship between LDL-c and Alzheimer's disease risk, either directly (non-randomised studies of LDL-c levels) or indirectly (non-randomised studies of statins, Mendelian randomisation studies using genetic instruments for LDL-c levels).

Once the set of relevant results were identified, effects were standardised to refer to the risk of Alzheimer's disease resulting from a "reduction" in LDL-c. For studies of statins, th. However, for both non-randomised studies and Mendelian randomisation analysis of lipid levels, the effect is usually reported per 1-SD increase in LDL-c. In this case, the effect estimates were inverted to ensure consistency across study designs.

&nbsp;<!----------------------------------------------------------------------->  

####	Assess risk and direction of bias in each result

For the sake of consistency, I mapped the different acceptable judgements in each risk-of-bias tool to a harmonised set of judgements: "Low", "Moderate","High". The exact mapping can be seen in Table \@ref(tab:robLevelsMapping-table). Of note, no mapping was performed for the critical risk-of-bias levels present in the tools for non-randomised studies. This is because current best practice in evidence synthesis is to exclude all studies at critical risk of bias for further quantitative synthesis.[@sterne2016]

&nbsp;<!----------------------------------------------------------------------->  
(ref:robLevelsMapping-caption) robLevelsMapping

(ref:robLevelsMapping-scaption) robLevelsMapping

```{r robLevelsMapping-table, message=FALSE, results="asis", echo = FALSE}
```
&nbsp;<!----------------------------------------------------------------------->  

In addition to assessing the extent of bias in each domain, as defined by the three levels detailed above, I attempted to record the predicted direction and type of bias. This was achieved via an additional question at the end of each bias domain, which asked assessors to predict the expected direction of bias in that domain. Note that this question is currently only formally included in two existing tools (ROB2/ROBINS-I), but I employed an identical approach during assessment of non-randomised studies of exposure and Mendelian randomisation studies. Acceptable responses to this question included: 

* "Favours experimental"/"Favours comparator" (defines an additive bias)
* "Towards null"/"Away from null" (defines a proportional bias)
* "Unpredictable"

As indicated in the options above, the response to this question is also used to determine the predicted type of bias (additive or proportional - see Section \@ref(tri-terminology)) in addition to the direction. For additive biases, determining the absolute direction of bias was simply a case of whether the bias shift the effect estimate to the left or right on an imaginary forest plot. For example, if a bias was predicted to favour the intervention, then the estimate would be shifted to the right.

In contrast, for proportional biases, whether the estimate should be increased or decreased proportionally depends on the current position of the point estimate relative to the null. For example, if the effect estimate represents a protective effect (below the null), then bias towards the null would be adjusted for by moving the effect estimate propotionally to the right. In contrast, if the effect of the intervention is harmful (effect estimate above the null), bias towards the null would be adjusted for by moving the effect estimate propotionally to the left. 

<!-- TODO The additive biases in this example figure should refer to favouring the comparator, meaning that the bias is pulling towards the intervention side (i.e. is making the comparator look better). -->

<!----------------------------------------------------------------------------->
 ```{r exampleDirectionSetup, include = F}
 ```

(ref:exampleDirection-cap) Illustration of calculating the absolute direction of biases (indicated by arrows), based on bias type. For additive biases, the direction is consistent regardless of the position of the effect estimate relative to the null. In contrast, the position of the effect estimate is accounted for when determining the absolute direction of proportional biases. 

(ref:exampleDirection-scap) Illustration of calculating the absolute direction of biases, based on bias type.

```{r exampleDirection, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:exampleDirection-cap)', out.width='100%', fig.scap='(ref:exampleDirection-scap)'}

knitr::include_graphics(file.path("figures/tri/exampleDirection.png"))

```
<!----------------------------------------------------------------------------->

Note that for some domains, only one type of bias is allowed. For example, in the confounding domains in the ROBINS-I/ROBINS-E tools, only the "Favours experimental"/"Favours comparator", and "Unpredictable" options are available, meaning that bias in this domain will always be considered additive. Additionally, the predicted direction and type of bias were not recorded for domains at "Low" risk of bias.

&nbsp;<!----------------------------------------------------------------------->  

#### Visualisation of extent and direction of bias

To aid with the triangulation exercise and to act as a sense-check, I created a new method to visualise the extent, direction and type of bias in each result to enable detailed comparison across different studies contributing to a synthesis. Similar to the standard paired forest plots introduced in Chapter \@ref(sys-rev-), these "bias direction" plots show the  level of bias across the domains in each study is reported using coloured blocks. However, in contrast to the previous plots, symbols are used to illustrate the predicted absolute direction of bias in that domain, as discussed in the previous section. Distinct symbol pairs are used to denote additive and proportional biases.

Convenience functions in the `triangulate` package (see Section \@ref(tri-software)) were used to preprocess risk of bias data for use with both bias-direction plots and adjusted meta-analyses, as discussed in subsequent sections. These bias direction plots themselves were created using the risk-of-bias visualisation tool described in Appendix \ref(?).

&nbsp;<!----------------------------------------------------------------------->  

####	Assign modifying values to risk/direction of bias
<!-- TODO Note that they are on the log scale - Lines 45-50 of addbias -->

Following definition of the extent, type and direction of bias in each domain, I assigned a prior distribution on the log scale to each combination. For example, a "high" additive bias in $j$th domain of the $i$th study is defined as $\delta_{i,j}^{\mathrm{High}}$ and uncertainty around this estimate is given by a distribution:

\begin{equation}
  \delta_{i,j}^{\mathrm{High}} = f(\mu_{i,j}^{\mathrm{High}}, \sigma_{i,j}^{\mathrm{High}})
  (\#eq:name)
\end{equation}

The sign of $\mu_{i,j}^{\mathrm{High}}$ is defined by the absolute direction of the bias. If the bias is expected to pull the effect to the left, $\mu_{i,j}^{\mathrm{High}}$ is given a negative sign, and if it is expected to pull the effect to the right, it is given a positive sign.

One key feature of the domain-based risk-of-bias tools is that the domains are considered interchangeable - i.e. a "high" judgement in one domain is equivalent to a "high" judgement in any other. As such, for this analysis, I assumed that the distributions assigned to each extent of bias were identical across all values of $j$, that is, were identical for all domains in the risk-of-bias assessment tool. To illustrate for additive biases:

$$
\delta_{i,1}^{\mathrm{High}} = \delta_{i,2}^{\mathrm{High}} = ... = \delta_{i,j}^{\mathrm{High}}
$$

and similarly

$$
\delta_{i,1}^{\mathrm{Moderate}} = \delta_{i,2}^{\mathrm{Moderate}} = ... = \delta_{i,j}^{\mathrm{Moderate}}
$$

Reasonable values for the position and spread of the prior distributions were informed by a previous reported expert bias elicitation exercise.[@turner2009] Using open data from that study, I calculated the mean and maximum values for the mean and variance of the adjustment distributions across all biases considered by that exercise (see Appendix \@ref(?) for more details on how these were calculated). For the purposes of this illustrative analysis and to highlight the generalised nature of the code used to perform the analysis (see Section \@ref(tri-software)), I used the calculated values to inform two sets of modifying distributions (Table \@ref(tab:priorsAdd-table)) for additive biases, and a single set for proportional biases. In the first scenario, the relationship between the position assigned to each additive judgement is linear. In the second scenario, the step from "moderate" to high" is twice that from "low" to "moderate". Across both additive and proportional biases, the variance of the "high" risk--of-bias judgement distribution was defined to be greater than that for the "moderate" risk-of-bias judgement.

&nbsp;<!----------------------------------------------------------------------->  

(ref:priorsAdd-caption) Prior distributions for extent and type of bias under two scenarios, on the log scale. Note that the distributions for proportional biases were kept consistent across the two scenarios.

(ref:priorsAdd-scaption) Additive bias distributions

```{r priorsAdd-table, message=FALSE, results="asis", echo = FALSE}
```

&nbsp;<!----------------------------------------------------------------------->  

<!-- TODO In the absence of any empirical data regarding the priors, I used the data from the expert elicitation approach to calculate both the mean and max. These estimates, in addition to conversations with topic experts -->

 <!-- TODO Link this to open data! -->

Where the direction of bias in a domain was unpredictable for a given result, the mean of the adjustment distribution for that domain was set to 0 but the appropriate variance for the recorded extent of bias was retained (e.g. for an unpredictable "high" assessment, the distribution would be $N(0,0.12)$). In other words, adjusting for bias in a domain with an unpredictable direction of bias has no impact on the position of the effect estimate, but does increase the uncertainty around it.

&nbsp;<!----------------------------------------------------------------------->  

####	Assessing and assigning modifying values to indirectness

An identical approach was employed to assess and assign prior distributions to the risk of indirectness in each result. The target question for each result was compared against the causal question of interest with respect to three domains (population, intervention/exposure, outcome), <!-- TODO CITATION NEEDED --> again using the scale of "Low/"Moderate"/"High" to quantify the extent of indirectness. All indirectness were defined _a priori_ as being proportional in nature, in line with previous work on this topic.[@turner2009]

As crude illustrative example, consider the causal question of the interest in this exercise, the effect of LDL-c in mid-life on Alzheimer's disease. Here, studies of lipids levels in this time period would require minimal adjustment, whereas studies examining statin use (indirect exposure/intervention) in late-life (indirect population) would be downweighted due to reduced relevance to the causal question.

&nbsp;<!----------------------------------------------------------------------->  

####	Combine in a bias-adjusted meta-analysis 

Using the the method reported in Turner _et al._,[@turner2009] total additive and proportional bias and indirectness were calculated for each result. Briefly,

<!-- TODO Talk about how total add/prop biases calculated -->

Once the total additive and proportional bias and indirectness for each result were computed, they were used to define an adjusted estimate for each result included in the synthesis.

Using the method defined in Turner _et al_,[@turner2009] the adjusted estimate for each result, $\hat\theta$, is defined as:

\begin{equation}
  \hat{\theta} = \frac{y_i - \mu_{i\beta}^{\mathrm{In}}\mu_{i\delta}^{\mathrm{In}} - \mu_{i\delta}^{\mathrm{B}}}{\mu_{i\beta}^{\mathrm{B}}\mu_{i\beta}^{\mathrm{In}}}
  (\#eq:adjusted-mean)
\end{equation}

The standard error of this estimate is then calculated as:

\begin{equation}
  \mathrm{SE}(\hat{\theta})=\left(\frac{1}{\mu_{i \beta}^{\mathrm{B}} \mu_{i \beta}^{\mathrm{In}}}\right)^{2}\left(s_{i}^{2}+\left(\mu_{i \beta}^{\mathrm{B}} 2+\sigma_{i \beta}^{\mathrm{B}}\right)\left(\hat{\theta}^{2} \sigma_{i \beta}^{\mathrm{In} 2}+\sigma_{i \delta}^{\mathrm{In} 2}\right)+\sigma_{i \beta}^{\mathrm{B}}\left(\hat{\theta} \mu_{i \beta}^{\mathrm{In}}+\mu_{i \delta}^{\mathrm{In}}\right)^{2}+\sigma_{i \delta}^{\mathrm{B} 2}\right)
  (\#eq:adjusted-se)
\end{equation}

Once each individual result has been adjusted, I performed a random effects meta-analysis using the unadjusted and adjusted (under the two scenarios defined above) results. <!-- TODO CITATION NEEDED -->

<!-- TODO Sensitivity analysis - set means to zero and only adjust for variance. Essentially adding uncertainty based on the amount of bias but not moving the effect estimate -->

&nbsp;<!----------------------------------------------------------------------->  

## Results

### Qualitative triangulation

```{r azd-text, echo = FALSE}
```

#### All-cause dementia

<!-- TODO Need to talk about fibrates here too -->

__Statins and all-cause dementia__

This conflicts with the findings of our analysis, where statin use was associated with an increased risk of all-cause dementia (`r anydem_text`). Some of the included studies in the meta-analysis specifically exclude vascular dementia from the definition of all-cause dementia,[@chao2015] which may limit the ability for comparison with our findings for the all-cause dementia outcome.

Additionally, a previous analysis of the THIN EHR database using a propensity-score matched analysis found a protective effect of statins on all-cause dementia (HR:0.81, 95%CI:0.69-0.96)[@smeeth2009]. 

&nbsp;<!----------------------------------------------------------------------->  

#### Alzheimer's disease

__Statins and Alzheimer's disease__

Our results are broadly in line with the findings of two distinct approaches examining the effect of statin treatment on subsequent Alzheimer's disease. No randomized trials of statins for the prevention of Alzheimer's disease have been reported, but a recent meta-analysis of 20 observational studies found statins were associated with a reduced risk of Alzheimer's disease (RR 0.69, 95% CI 0.60–0.80) with stronger evidence than observed in our analysis.[@poly2020] This review included case-control studies and analyses likely to be at risk of immortal time bias, which may account for the discrepancy with our findings. Additionally, a recent Mendelian randomization study examining the effect of genetic inhibition of HMGCR on Alzheimer’s disease (a genetic proxy for statin treatment) provided equivocal evidence (OR: 0.91, 95%CI: 0.63-1.31) but was consistent with our results.[@williams2020]

Our additional analyses stratified by statin properties found little evidence of differences in associations of lipophilic and hydrophilic statins and incidence of Alzheimer’s disease, consistent with a recent meta-analysis of observational studies.[@chu2018]

&nbsp;<!----------------------------------------------------------------------->  

#### Vascular dementia

__Statins and vascular/other dementia__

Far fewer studies have tested the association between lipid-regulating agents and vascular dementia or other dementias. A recent review found four observational studies examining the association of statins and vascular dementia found limited evidence for an effect (RR:0.93, 95% CI 0.74–1.16).[@poly2020] This contrasts with the harmful association found in our analysis (`r vasdem_text`). When stratifying by lipid properties, lipophilic statins were more harmful than hydrophilic statins in vascular dementia, potentially due to their ability to cross the blood brain barrier.

&nbsp;<!----------------------------------------------------------------------->  

__Other drug classes__

Apart from statins, few studies examining a lipid-regulating agent have been reported (Chapter \@ref(sys-rev-methods-heading)/\@ref(sys-rev-results-heading)). 

One of the few classes for which a evidence was available were fibrates, which found little evidence of an association with all-cause dementia was identified,[@ancelin2012] inconsistent with our finding that patients prescribed fibrates had higher all-cause dementia risk than those prescribed other lipid lowering agents.

A previous Mendelian randomization study found little evidence that genetic variants that proxy for ezetimibe affect risk of Alzheimer’s disease (OR: 1.17, 95%CI: 0.73-1.87),[@williams2020] consistent with our findings. Note that this study was published in 2020 and so was not included in the review.

&nbsp;<!----------------------------------------------------------------------->  

### Quantitative triangulation

#### Single study

Explain how example study was chosen

Show result and bias

Reproduce version of Table 2 rom the "proposed method" paper for indirectness

Total additive bias (on the log scale) was `r hold()`. Similarly, total additive indirectness was (), 

Calculate internal-bias adjusted

`r hold()`

The unadjusted effect for this study was `r hold()` and the adjusted effect estimate for this study was `r hold()`

In this study, there were 3 domains at greater than low risk of bias: Bias due to confounding, Bias due to definition of the outcome, and Bias in the selection of the reported result. 

In Domain 1, the study did not adjust for ApoE4, which is predicted to mask any true assocation between statins and . As such, the bias is predicted to _favour the comparator_ and so the absolu

In Domain 5, there was a moderate risk of differential miclassification on the basis of the exposure, and so the predicted direction of bias in this domain is to _favours the intervention_. As such, the absolute direction of bias is to the left.

For consistency with the other NRSI, in the absence of a protocol, bias in the selection of the reported result is assumed to be _away from the null_. Given the position of the effect estimate below the null (`r hold()`), the absolute direction of bias in this domain is to the left.

<!----------------------------------------------------------------------------->
(ref:biasDirectionSingle-cap) Bias direction plot for a single study showing the predicted direction of bias in each domain. Additive biases are characterised using arrows, while the proportional biases are denoted using $<$ and $>$. A question mark indicates that the direction of bias was unpredictable.

(ref:biasDirectionSingle-scap) Bias direction plot for a single study
```{r biasDirectionSingle, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:biasDirectionSingle-cap)', out.width='100%', fig.scap='(ref:biasDirectionSingle-scap)'}
knitr::include_graphics(file.path("figures/tri/midlife_AD_single.png"))
```
<!----------------------------------------------------------------------------->

&nbsp;<!----------------------------------------------------------------------->  

#### Case study: effect of LDL-c at midlife on Alzheimer's disease

From the data sources identified in Section \@(), I identified X results relevant to my causal question of interest. <!-- TODO CITATION NEEDED will need to cite these! --> The extent, type and direction of predicted bias for each result can be seen in the bias-direction plot presented in Figure \@ref(fig:ldlAdBiasDirection), stratified by study design.

<!-- Question - Hypercholesterolemia should not be included here, as it is focused on total cholesterol rather than specifically LDL-c, right? -->  

&nbsp;<!----------------------------------------------------------------------->  

```{r ldlAdBIAMA, include = F}
```

(ref:ldlAdBiasDirection-cap) Bias direction plot, summarising the internal biases related to effect of LDL-c on Alzheimer's disease, stratified by study design.

(ref:ldlAdBiasDirection-scap) Bias direction plot, summarising internal biases related to the 

```{r ldlAdBiasDirection, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:ldlAdBiasDirection-cap)', out.width='100%', fig.scap='(ref:ldlAdBiasDirection-scap)'}
knitr::include_graphics(file.path("figures/tri/midlife_AD.png"))
```
<!-- TODO Bias direction plot is not producing subgroup test for some reason -->

&nbsp;<!----------------------------------------------------------------------->  

The results of the unadjusted and the bias-/indirectness-adjusted (under the Scenario 1 of additive biases) are shown in Figure \@ref(fig:fpLdlAd). I observed no substantial change to the overall effect (unadjusted `r unadj_effect`; adjusted `r adj_effect_scenario1`), though adjustment for bias and indirectness substantially reduced the heterogeneity between studies (unadjusted $\tau^2$ = `r unadj_tau2`, $I^2$ = `r unadj_I2`; adjusted  $\tau^2$ = `r adj_tau2`, $I^2$ = `r adj_I2`). However, as can been seen from the right panel in the figure, this reduction in heterogeneity between studies is largely achieved via a reduction in precision.

To explore the different impacts of the two defined scenarios for additive bias, I plotted these:

<!-- TODO How effect are fibrates at lowering triglycerides? is it a direct effect, or are there alternative -->

<!-- TODO Finish -->

&nbsp;<!----------------------------------------------------------------------->  

<!-- TODO This should really be stratified by type -->
<!-- TODO Standardise effect estimates to same direction -->
<!-- TODO Need to add my own evidence -->


(ref:fpLdlAd-cap) Random effects meta-analysis using unadjusted and bias-/indirectness-adjusted results.

(ref:fpLdlAd-scap) Random effects meta-analysis using unadjusted and bias-/indirectness-adjusted results.

```{r fpLdlAd, echo = FALSE, results="asis", fig.pos = "H", fig.cap='(ref:fpLdlAd-cap)', out.width='100%', fig.scap='(ref:fpLdlAd-scap)'}
knitr::include_graphics(file.path("figures/tri/fp_paired_midlife_ldl_ad.png"))
```

&nbsp;<!----------------------------------------------------------------------->  

#### Case study: effect of triglycerides at midlife on vascular dementia



## Discussion

<!-- IDEA Do turner et al standardise effect direction? -->  

While this analysis may be biased from the non-empirical bias adjustment factors, at the very least, it acknowledges the the uncertainty of evidence via the widening of confidence intervals. 
No less problematic than the analysis fo biased estimates in a meta-analysis which does not account for bias.

### Summary of findings

This chapter has narratively synthesised the existing and new evidence identified and produced by the previous chapters, highlighting the absence of any consistent association between any blood lipid and any dementia outcome in the context of the bias in each approach.

In addition, it has sought to provide a generalised framework for quantitative triangulation, building on existing methods for systematic domain-based risk of bias assessment and bias-/indirectness-adjusted meta-analysis. While a lack of information on the prior distributions of bias and indirectness in non-randomised studies precluded, to illustrate the method, I considered the example causal question of the effect of mid-life LDL-c on Alzheimer's disease risk derived from a previous expert elicitation exercise.

&nbsp;<!----------------------------------------------------------------------->  

###	Limitations

<!-- TODO See discussion of original Turner paper -->

#### Defining reasonable prior distributions for bias and indirectness

Allowing for the strong assumption that 

The key limitation of this quantitative synthesis presented in this chapter is the ambiguity

It is the reason that only one causal question is addressed as a case study, as to base clinical recommendations on a method dependent on non-empirical values would be inappropriate.

Meta-epidemiological studies on the effect of different methodological issues on results exist for randomised controlled trials,[@amer2021; @page2016] suggesting that X, Y and Z.

However, there is substantially less , arguably because of the absence of clear
Many meta-epi studies of non-randomised studies assume bias at the study-design level, similar to the early triangulation frame-work, rather than considering the actual biases deemed to be present in a given result. In this scenario, study

Potential future meta-epidemiology studies should begin to create these datasets. 

New software for performing risk of bias assessments, being developed by the Bristol Appraisal and Review of Research group has this as a secondary methodological aim.

Much of the attention to date has been on assessing the impact of different sources of bias on effect estimates has focused predominantly on randomised controlled trials. 

For example, a study examining the effect of found that only a subset of domains appear to impact the result, and that this effect is modest (10% change).[@savovic2018] However, this work examined RCTs, and these findings may not hold for other non-randomised study designs. <!-- TODO Double check this citation actually says what you think it does! -->

<!-- TODO Pretty sure Julian sent me some papers on have suggested values for randomised controlled trials (e.g. effect of poor blinding etc) -->

Similar there are several examples of usmeta to define priors for other statistical terms in meta-analysis. For example, previous work has looked at defining prior distributions of heterogeneity across different topic areas using a large collection of meta-analyses from the Cochrane Collaboration.<!-- TODO Cite turner etc -->

<!-- TODO Talk about the fact recent paper does not favour bias-adjustment -->

Elicitation and bias-adjusted not as favoured versus weighting [@stone2020] <!-- TODO Check this is actually what this reference says --> though weighting at the overall risk-of-bias level loses some of the information contained in domain-level based assessments. 

In future, domain specific. In fact, it may also be more reasonable for domains such as confounding to adjust on a per-confounder basis. In the approach, prior distributions are assigned to each of the confounding domains prespecified as part of the ROBINS-I tool. Then, rather than assigning a domain level distrbution based on an arbraty judgement of how many important confounders are missing, the result is adjusted for each confounder not accounted for in the original analysis. As an example, ApoE4 is a much stronger confounder of the LDL-c than a single lifestyle indicator.

<!-- TODO Talk about sensitivity analysis that only added variance rather than moving the point estimate, and highlight that this is a way to account for bias without having to make strong predictions about the direction of bias in a given domain. -->

Estimates of modifying means might be conservative in relation to some potentially strong confounders. A previous simulation study estimated that ApoE4 would induce a RR of 1.09 with risk of dementia per 1-SD increase in LDL-c.[@iwagami2021a]



#### Subjectivity of bias-/indirectness-assessment

<!-- TODO Add text here on the subjectivity of qualitative risk of bias assessment and cite ROBINS-I to say that risk of bias is hard. Note that this will apply  -->

A key issue in this analysis is the subjectivity of both the 


Key problem here is if the rigourness of the tools is not equivalent. This is less of an issue for the ROB suite of tools (RoB 2.0, ROBINS-I, ROBINS-E). This can be illustrated by the Ostergaard _et al._ study having low risk of bias. 

This is particularly problematic given the default of the ROBINS-I and ROBINS-E tool to require a "Moderate" judgement in the confounding domain. It means that, if the MR tool is insufficiently assessing bias in MR studies, the best performed cohort study (low risk of bias across everything other that confounding) will  always downweighted versus potentialyl a poor MR study.

Similarly,

&nbsp;<!----------------------------------------------------------------------->  

#### Low and critical risk of bias

As illustrated in Table \@ref(tab:robLevelsMapping-table), studies at critical risk of bias were not included in the analysis.

one potential limitation of the  - however, the estimation of an appropriate adjustment value for these studies would be substantially more challenging.

In any case, it represented a small number of studies.s

A further issue is the "Low" risk of bias domain. In this proof-of-concept analysis, I assumed that domains at "Low" risk of bias did not require any adjustment. However, "Low" risk of bias is not equivalent to the absence of bias, and potentially should still be adjusted for. In this case, defining the predicted direction of bias would be challenging in the absence of obvious sources of bias (particularly given how challenging it can be when sources of bias are evident within a domain). 




&nbsp;<!----------------------------------------------------------------------->  

### Strenghts

This approach has a number of advantages. One of the key ones is modifying distributions of each level of bias could be defined _a priori_ in contrast to the .

In addition, the generalised framework will allow for future researchers to apply (see Section \@ref())

Appreciation that both the risk of bias and indirectness of a result should be assessed is growing. Indeed, some existing risk of bias for the assessment of diagnostic test accurary[@whiting2011a] and prediction models[@moons2019] consider indirectness (termed applicability in these tools) alongside the assessment of bias. <!-- TODO Cite PROBAS and QUADAS --> <!-- TODO CITATION NEEDED cite paper that shows that ROB is not being intergrated into synthesis --> The approach proposed here will capitalise on this, providing users of domain based tools with a further avenue by whih to incorporate the results of their risk-of-bias assessments quantitatively.

Additional if users are interested in only a summary of the evidence rather than assessing results in relation to a target question, then internal biases can be adjusted for on their own by setting the indirectness distributions to $N(0,0)$.

The extent of a bias in a domain is unlikely to map accurately across the same domains in different studies, which

It for this reason that in previous attempts at bias-/indirectness-adjusted meta-analysis, the extent of bias in each study was assessed via a elicitation process using a panel of methodologists and topic experts.[@thompson2011; @turner2009; @wilks2011] However, this approach is potentially subject to misclassification of the impact of bias on the basis of the results, as there is no way to ensure that results at a similar level of bias for confounding (for example) are being adjusted by the same amount across studies. As an illustrative example, if experts are influenced by the knowledge of the effect estimate in a study, then a result demonstrating a stronger protective effect may receive greater modification than a study at the same "risk" of confounding but with a more modest effect. This is likely to be part where experts have preconceived ideas about the true effectiveness of the intervention.

In this case, separating the assessment of bias from the assignment of modifying values to each level of bias will limit the potential for. Alternatively, reasonable modifying distributions for each level of bias could be defined _a priori_ by the study team using the elicitation procedure detailed previously,[@turner2009] similar to how important confounders and co-interventions are defined in advance when performing ROBINS-I/ROBINS-E assessments.[@sterne2016]

&nbsp;<!----------------------------------------------------------------------->  

\newpage

### Future research

As the need and appetite for synthesis of different sources of evidence (trials, non-randomised studies, etc.), future iterations of the risk of bias tools should take this into account. Simple steps like harmonising the risk of bias levels across tools would be a good first move towards a more integrate suite of tools. Similarly, software that implements the risk-of-bias tools should both allow for direction of bias question and carefully consider how this data will be exported.

While the limitations inherent to this method are important, and limit the , they reflect a more detailed appreciation of the complexities of risk of bias assessment and triangulation as whole (i.e. not applying expected directions of effects to an entire category of studies ). 

This approach also builds on existing approaches employed previously by "exploding out" the results of a systematic review/meta-analysis and considering the effects of bias in each individual result separately. This more granular approach is to be preferred over assigning a bias judgement and direction to the summary effect produced by a meta-analysis,  which may mask the different biases applicable to each unique result.

A key example of a useful future study in this domain would be the mining of maximally adjusted vs. unadjusted estimates from abstracts from primary studies to assess the impact of insufficient confounding by topic. However, these datasets could also be built from systematic reviews of a topic, as they would already be gruped by reserach domain and provided the risk of bias data is shared, provide a ready source of information

In the mean time, the extent of the impact of knowledge of the results could be analysed using existing data. For example, a re-analysis of the data presented in a recent paper where both expert elicitation and structured 

Future research could and should also take into account bias at the analysis level in terms of missing evidence. For example, the set of previously published NRSE included in the case study were found to be at high risk of bias from missing evidence (see Figure \@ref(fig:lipidFractionsAD) in Chapter \@ref(sys-rev-results-heading)). Ideally, a quantitative triangulation framework would further account for this proportional evidence-level bias (as bias due to missing evidence is most likely to bias away from the null due to publication bias mechanisms), in addition to result-specific biases.

<!-- QUESTION - Can you meta-analyse meta-analysis results? As in, have a two-stage approach where you pool by evidence source, investigate bias at analysis level within evidence source, adjust these within-evidence-source results for ROB_ME bias, then pool them for final estimate? -->


&nbsp;<!----------------------------------------------------------------------->  

### Triangulation as an extension of evidence synthesis

Triangulation, both qualitative and quantitative, should be considered an extension of evidence synthesis, and so. Triangulation exercises should be based on comprehensive systematic reviews to create. If needed, evidence gaps can be addressed through additional studies, as in the case of this analysis, 

Compare and contrast with the nice example presented in the triangulation paper - realities of non-exemplars is that it is very hard to get this right. Also highlight the issue with assigning a direct of bias in many studies

I hope this presents step forward in how researchers think about and visualise triangulation at the result level, rather than simply saying that certain evidence sources a

&nbsp;<!----------------------------------------------------------------------->  

### Outputs {#tri-software}

There are two key outputs from this project. The first is the `trinagulate` R package. Personal communication with the authors of the original method resulted in the STATA code to implement the bias-/indirectness-adjusted model. This has since been generalised as part of the `triangulate` R package to enable other users to apply the approach detailed here. The package allows for preprocessing of domain-based risk-of-bias data to correctly identify the direction of the bias relative to the effect estimate, use of domain-specific prior distributions, calculation of bias/indirectness-adjusted estimates for each result, and synthesis these adjusted results in a standard random-effects meta-analysis. All meta-analyses conducted within the package are implemented using the `metafor` R package. <!-- TODO CITATION NEEDED and cite in Sys rev chapter too! -->

Generalised version of code, allowing for different distributions in each domain of bias (which will be handy once we get a better idea of what they should be).

Annotated example dataset for the LDL-c/Alzheimer's disease causal question is the second key output. Available via the `triangulate` package, this data will give developers of new triangulation methods an example dataset on which to test developments, something which seriously hindered development of this project. This also ties with the idea of open data that has been a consistent theme throughout this thesis.

An additional note is that without the open data sharing of the by-assessor elictation data from, which i sued in this analysis to frame the modifying values assigned to 

&nbsp;<!----------------------------------------------------------------------->  

## Conclusion

Triangulation is a promising developing field, somewhat hamstrung by the limited understanding of the impact of biases at the meta-epidemiological level.

In this chapter, I have presented a new method of visualising both the level and expected direction of bias inherent to each result, and suggested how this could be incorporated with a bias-adjusted meta-analysis approach to work towards a generalised quantitative triangulation framework. 

Finally, I've highlighted the limitations of this method, as the correct distributions of modifying values in each risk-of-bias domain should be driven by meta-epidemiological studies which do not yet exist, framing them as opportunities for future research.

This chapter has demonstrated a repurposed framework for quantitative triangulation, exploiting existing methods in evidence synthesis and developments in the assessment of different risks of bias. 

Future quantitative triangulation should move beyond the concept of comparing results at the approach level, and instead focus on the inherent threats to the internal validity and directness of each specific result relevant to the causal question. While this makes the process both more labour intensive and complex, 

It also introduce a new way to visualise the biases at work in a particular result, rather than making assumptions about the type and directions of bias at the study design level as suggested by previous work on this topic. 

Finally, it highlighted the limitations of current methods for triangulation in the absence of informative priors for the impact of biases across the 

The implications of the synthesised work of this thesis presented in this chapter to clinical practice, public health and future research is considered in the following chapter.


\newpage

## References



